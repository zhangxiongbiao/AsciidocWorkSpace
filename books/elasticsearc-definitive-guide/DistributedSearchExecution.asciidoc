= 深入理解分布式搜索过程
:sectanchors:
:imagesdir: images

分布式搜索比基本的分布式 CRUD 请求（分布式文档存储中提过） 要复杂的多。

CRUD 请求时都会有文档的 index、type、id 及路由值等，所以我们可以确定集群中哪一个分片上有这个文档。

而搜索请求就更复杂了，因为我们并不知道哪些文档会匹配你的查询，而且匹配的文档可能在集群中的任意一个分片上。所以一个查询请求需要去请求索引上的每一个 *分片（这里指主或备分片中任意一个）* ，然后来看是否有文档匹配到上你的查询。

但是从所有分片（主或备中任意一个）中找出匹配上查询的文档只是第一步，每个分片上匹配到的文档还需要合并到一起，然后再按照分页取出某一页数据返回。因为这个原因，所以一个搜索请求分为两步：查询数据与获取数据。

== 查询数据阶段

在初始化查询阶段时，搜索请求被广播到所有的分片（任意一个主或备份分片）上。每一个分片本地执行这个搜索请求，然后将匹配的文档放入到一个带优先级的队列中。

.Priority Queue
****
一个带优先级的队列就是保存top-n（最匹配的N条）个匹配文档的队列。而这个队列的大小取决于查询请求中的 _from_ 与 _size_ 。

例如：
[source,js]
----
GET /_search
{
    "from": 90,
    "size": 10
}
----
则队列的大小为 *from+size=100* 。这里要取 *from+size* 是因为每个分片上取完数据后还需要排序的原因。

[NOTE]
====
因为最终排序的关系，绝大部分数据会丢弃。优先级队列中为了减小空间占用，只存储了匹配到的文档的 _docId_ 与 _sort value_ 。
====
****

.分布式检索查询阶段
image::elas_0901.png[]

.上图可以用以下3个步骤描述：
. 客户端发送搜索请求到节点3， 节点3此时创建一个空的带优先级队列，队列大小为 *from+size*
. 节点3将请求转发到索引中每一个分片（主或备份分片）上，每一个分片本地执行搜索请求并将匹配的结果放到它本地的优先级队列（大小同样为 *from+size* ）中。
. 每一个分片将优先级队列中 _docIds_ 与 _sort values_ 返回给对应的协调节点（节点3），节点3然后将所有的请求合并到它自己的优先级队列中形成一个按排序值排好序的全局队列。


[TIP]
====
跟客户端通讯的节点，也被称为协调节点，例如上面的节点3。协调节点需要转发请求到所有分片，而且需要收集所有分片返回的数据，再根据分页设置取出对应的数据并返回给客户端。
====

[NOTE]
====
协调节点转发请求至各分片（主或备）时采用轮循机制，就是在主或备之间轮循以确保能平摊压力。
====

协调节点将所有分片上的数据合并到自己的优先队列中并形成一个全局的排好序的文档集合后，查询阶段就完成了。

== 获取数据阶段

由于在查询阶段，优先级队列中只存储了 _docIds_ 与 _sort value_ ，所以还需要根据 _docIds_ 去获取真正的数据。

.分布式搜索获取数据阶段
image::elas_0902.png[]

.分布式搜索获取数据阶段由以下几个步骤组成：
. 协调节点决定由哪些文档是真正需要获取的，根据 _docIds_ 发送一个 _MGet_ 请求至各个相关的分片。
. 所有的相关分片获取到对应的文档（填充 _source， 填充高亮片段）后，将文档返回给对应的协调节点
. 当所有的分片将文档都返回后，协调节点再将结果一起返回给客户端

协调节点最先处理的是要决定哪些文档才是真正需要去获取的。比如你的查询指定的是 {"from":90,"size":10} ，那就意味着最开始的90个文档都需要被丢弃，你只需要下10个文档。然后协调节点只需要发送 _MGet_ 请求获取这10个文档即可。


.深层分页
****
搜索支持 _from_ 与 _size_ 参数，但是有些限制。在上面的查询阶段提到过，每一个分片都自己建立了一个优先级队列，大小为 *from+size* ，然后队列所有数据需要返回给协调节点。然后协调节点需要对 *number_of_shards * (from + size)* 个文档进行排序，再从排序好的文档列表中，找到 _from_ 与 _size_ 指定的那些文档。

这个时候分页限制就取决于你指定的 _from_ 和 _size_ 大小，以及 *number_of_shards*（主分片数量）和你的硬件了。分页越深，耗费的 CPU 、 内存、 带宽越大。 出于这个原因，应该尽量避免深分页。

一般情况下，人们用搜索时一般只分翻几页后就换一个其它的条件来检索了，也就是说人为地去深分页概率比较低。一般来说，只有黑客与网页爬虫才会去深分页让你的服务器崩溃。


如果你需要从你的集群中获取大量的文档，此时建议使用 _scroll_ 查询（它会禁用排序）。
****


== 查询参数
一些查询参数可以影响搜索过程

=== preference
_preference_ 参数可以用来决定由哪些分片来处理你的查询请求。它接受的参数值有：

image::preference.png[]

然而，上面的参数值中最常用的是 Custom value ，来避免结果跳动。

.Bouncing Results
****
假设你根据 _timestamp_ 字段进行排序，现在有2个文档拥有相同的 _timestamp_ 。 因为查询请求都是在可用的主、备分片上轮循的，所以就可能出现这2个文档在主分片中是一种顺序，在备份分片中又是一种顺序。

这个就是结果跳动的情况，每当用户刷新他的页面，返回的结果是不同的顺序。这个问题可以用 _preference_ 参数指定自定义的字符串来避免，例如指定用户的 _session id_ ，这样用户每次访问都是在同一个分片上。
****

=== timeout
默认情况下，分片都是各自处理匹配到的数据，然后返回给协调节点，由协调节点依次合并所有结果。

这也就是说，一个搜索请求的耗时由处理请求最慢的分片（多个分片处理请求是并行的）耗时加上最后合并结果耗时组成。

_timeout_ 参数用于告诉分片在返回数据给协调节点前它们有多长时间用来处理数据，这也就是说，如果没有足够的时间处理所有数据，这个分片将会放弃剩余的数据直接将已处理的数据返回给协调节点（有可能压根都没有已处理数据）。


在搜索的响应信息中可以看出查询请求是否超时了。

[source,js]
----
 "timed_out":     true // <1>
----
<1> 为 _true_ 表示超时了

[WARNING]
====
_timeout_ 只是一个尽力而为的操作，这里也是有可能有些查询耗时还是会超过分配的 _timeout_ 时间。主要有下面两种方式：

. Timeout 检查是基于每一个文档的。然而，有一些查询类型在对文档进行匹配之前要做大量的准备工作，而这些准备工作消耗的时间是不会计算在 _timeout_ 之内的，所以这些准备工作耗时太长时将会使查询耗时超过分配的 _timeout_ 时间。
. 因为 Timeout 检查是基于每个文档的，所以就有可能上一个文档的匹配计算耗时太长，直到下一文档被计算时才会检查是否超时。例如，此时如果上一文档执行了写的脚本（该脚本中有个死循环），那么这种情况下，就会一直卡死在那， _timeout_ 也不会起作用。
====

=== routing
在 “分布式文档存储章节” ，我们讲过自定义路由参数可以在索引数据时决定文档存储到哪些分片上。在搜索时，为避免在所有分片上找匹配文档，你也可以指定路由参数来决定在指定的分片上查找匹配的文档。

[source,js]
----
GET /_search?routing=user_1,user2
----

这个技术通常用于超大的搜索系统来提高搜索效率。

=== search_type
默认的搜索类型为 `query_then_fetch` 。有时，你可能希望明确指定搜索类型为 `dfs_query_then_fetch` 来提高相关度评分的准确性。

[source,js]
----
GET /_search?search_type=dfs_query_then_fetch
----

`dfs_query_then_fetch` 会有一个预查询阶段，它会从所有涉及到的分片中提取词频率然后再算全局的词频率。后面会深入讲解。

== Scroll
滚动查询用于高效地从 _ES_ 中获取大部分数据，它不会排序也不会深分页。

_Scrolling_ 允许我们初始化一个查询并且持续一批批地从 _ES_ 中取数据。


深分页的主要性能损耗在于对结果集的全局排序，但是如果我们禁用了排序，那么将以非常廉价的性能损耗获取到所有的文档。为了禁用排序，我们对 `_doc` 字段进行排序（不指定排序时，默认是以 `_score` 进行排序）。

[source,js]
----
GET /old_index/_search?scroll=1m //<1>
{
    "query": { "match_all": {}},
    "sort" : ["_doc"], // <2>
    "size":  1000 // <3>
}
----
<1> 保持滚动窗口1分钟，1分钟后将自动清除资源。意味着过1分钟后，你再拿返回的 *scroll_id* 去取数据时将取不到。
<2> 按 *_doc* 进行排序
<3> 指定返回的结果集大小为 1000

此时响应将返回一个 *scroll_id* ，然后再根据 *scroll_id* 获取下一批数据即可。

[source,js]
----
GET /_search/scroll
{
    "scroll": "1m", // <1>
    "scroll_id": "cXVlcnlUaGVuRmV0Y2g7NTsxMDk5NDpkUmpiR2FjOFNhNnlCM1ZDMWpWYnRROzEwOTk1OmRSamJHYWM4U2E2eUIzVkMxalZidFE7MTA5OTM6ZFJqYkdhYzhTYTZ5QjNWQzFqVmJ0UTsxMTE5MDpBVUtwN2lxc1FLZV8yRGVjWlI2QUVBOzEwOTk2OmRSamJHYWM4U2E2eUIzVkMxalZidFE7MDs=" //<2>
}
----
<1> 再次设置向下滚动的超时时间
<2> 批处理的ID


[NOTE]
====
尽管上面指定了 _size_ 为1000条，但是每一批次里可能返回 `size*number_of_primary_shards` 个文档回来。
====
