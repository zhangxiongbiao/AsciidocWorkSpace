= 分布式文档存储
:imagesdir: images

== 路由文档至分片
当你索引一个文档， 它被存储在单独一个主分片上。 Elasticsearch是如何知道文档属于哪个分片的呢？当你创建一个新文
档， 它是如何知道是应该存储在分片1还是分片2上的呢？

这个过程中不能随机存储文档至分片的，因为存储完后我们还需要检索文档（随机存将导致将来无法检索到文档）。实际上，这是由一个简单的公式（算法）决定的。

[source,js]
----
shard = hash(routing) % number_of_primary_shards // <1>
----
<1>  产生的 _shard_ 分片位置永远在 0到number_of_primary_shards - 1之间

_routing_ 参数可以为任意的字符串，而它默认是文档的 *_id* 字段（_id可以为生成的和自定义的）。

这也正说明了为什么 _shard_ 的数量在索引创建时指定后再不能修改了。
如果主分片的数量可以更改的话，那么文档都将不能找到了。

[TIP]
====
所有文档级别的 _API_ 都可以接收一个 _routing_ 参数。
====

自定义的 _routing_ 值可以保证所有相关的文档都存储在同一 _shard_ 中。

== 主、备分片如何交互

.三节点集群
image::elas_0401.png[]

我们可以将请求发送给集群中的任一节点，每一个节点都是完全有能力处理请求的。每一个节点都知道文档在集群中的位置，也能将请求转发到指定的节点。

== 创建、删除文档

创建、索引、删除文档都操作都是写操作，所以必须保证在主分片上操作成功之后再复制到其它备份分片上。

.创建或删除单个文档
image::elas_0402.png[]

这里就是必须保证在主、备分片上都操作（创建、删除、索引文档）成功的步骤：

. 客户端发送请求至 _Node1_
. _Node1_ 根据文档的 _id_ 算出了该文档所属的shard为0。然后将请求转发给 _Node3_ （因为上面是0的主分片）
. _Node3_ 在主分片(P0)上执行了请求，如果请求成功了，它将把请求转发给 _Node1_ （R0） 和 _Node2_ 上的 （R0）。 如果所有的备份分片所在的节点都执行成功了， _Node3_ 将报告成功给最初的协调节点 _Node1_ ，再由 _Node1_ 将成功响应给客户端。

当请求成功响应到客户端时，此时文档已经在所有的主、备分片上成功执行了。所以你的修改是安全的。

这里也有一些可选的请求参数来影响这个过程。

replication:: 可选值、sync和async（默认为sync）。如果设置为async则请求到达上图中的 _Node3_ 上的P0时，如果请求成功则立即返回。而此时则是异步将修改同步到备份分片上，所以客户端收到请求成功的话，也不能确定在备份分片上的修改是否成功了。

consistency::
可选值：one（只要主分片激活即可）、all（所有分片都需要激活才行）、quorm（满足法定人数的分片数被激活才可以）。数据一值性，默认情况下 _ES_ 为了保证同步到备份分片上的请求能正确执行。 _ES_ 要求至少有一个法定人数上以上的分片是激活的，否则此时执行索引或删除文档都将失败。

法定人数的计算公式如下：
[source,js]
----
int( (primary + number_of_replicas) / 2 ) + 1  // <1>
----
<1> number_of_replicas 指的是在配置文件中指定的index.number_of_replicas的数值，默认是为1的。而非备份分片个数的总量。


.示例
[source,js]
----
int( (primary + 3 replicas) / 2 ) + 1 = 3
----
如，假如有3个备份，而你现在只启了两个节点的话，那么你此时做增加、删除文档操作时会受到默认的法定人数的限制，将无法执行增加、删除操作。

[TIP]
====
默认情况下，出现法定人数限制时，操作会有默认的1分钟超时时间。 _ES_ 会默认等待1分钟才给出报错，因为有可能其它节点此时正好加入集群中呢。
====

timeout::
如上面的提示所提到的，在做增加、删除文档等操作时，如果受法定人数限制无法进行操作时，会有默认的1分钟等待时间。这个默认的超时时间可以通过 _timeout_ 参数进行指定，如 timeout=1s、timeout=100ms

== 检索一个文档

一个文档可以从其所属的主分片检索，也可以从其余的备份分片中检索出来。如下图所示：

.单个文档的检索
image::elas_0403.png[]

如下是上图操作中涉及到的步骤：

. 客户端发送一个 _Get_ 请求至 _Node1_
. _Node1_ 根据文档的 _id 算出其所属的分片为0，而分片0(主、备)在所有的节点中都存在，此时将请求转发至 Node2 （转发的负载默认是轮循机制）
. _Node2_ 检索出文档，并返回给 _Node1_ 。

== 局部更新一个文档
_Update api_ 组合了 _read_ 与 _write_ 的操作。

.局部更新文档
image::elas_0404.png[]

上图操作步骤如下：

. 客户端发送请求至 _Node1_
. _Node1_ 根据请求要修改的文档的 _id 算出其分片为0，此时将请求转发至有主分片0的 Node3
. _Node3_ 先检索出要修改的文档，然后应用要修改的内容在主分片0上。如果该文档已经被其它 _process_ 修改过了，那么将重复指定次数（retry_on_conflict），否则放弃。
. 如果 _Node3_ 成功更新了该文档， _Node3_ 将把更新后的文档并行更新到其它节点上的备份分片。当所有的备份分片都返回成功后， _Node3_ 将返回成功状态给协调节点 _Node1_ ，然后 _Node1_ 再返回成功状态响应返回给客户端。

[TIP]
====
_Update api_ 可以接收 _routing_ , _replication_ , _consistency_ , _timeout_ 参数。
====

== 多文档模式
多文档操作： _mget_ 与 _bulk_

多文档操作时，将会把多个文档操作的请求拆分为单独的文档操作然后并行分发到各个对应的节点上来处理。

.使用 _mget_ 获取多个文档
image::elas_0405.png[]


.使用 _bulk_ 操作多个文档
image::elas_0406.png[]

== bulk格式解释
为什么 _bulk_ 的格式如此渣，主要出于效率考虑。如果文档格式太 _pretty_ ，那么一是会造成网络流量大，二是造成 _ES_ 解析请求变得复杂。这样一来降低了请求的效率。
